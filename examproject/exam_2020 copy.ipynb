{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Imports\n",
    "\n",
    "import numpy as np\n",
    "from scipy import linalg\n",
    "from scipy import optimize\n",
    "import sympy as sm\n",
    "import scipy as sp\n",
    "from scipy import interpolate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following **linear equation:**\n",
    "\n",
    "$$y_i = \\beta_0 + \\beta_1 x_{1,i} + \\beta_2 x_{2,i} + \\epsilon_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume you have access to data of the **independent variables** ($x_{1,i}$, $x_{2,i}$) and the **dependent variable** ($y_i$) for $N$ individuals, where $i$ indexes individuals. The variable $\\epsilon_i$ is a mean-zero **stochastic shock**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume the **data generating process** is given by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DGP(N):\n",
    "    \n",
    "    # a. independent variables\n",
    "    x1 = np.random.normal(0,1,size=N)\n",
    "    x2 = np.random.normal(0,1,size=N)\n",
    "    \n",
    "    # b. errors\n",
    "    eps = np.random.normal(0,1,size=N)\n",
    "    \n",
    "    extreme = np.random.uniform(0,1,size=N)\n",
    "    eps[extreme < 0.05] += np.random.normal(-5,1,size=N)[extreme < 0.05]\n",
    "    eps[extreme > 0.95] += np.random.normal(5,1,size=N)[extreme > 0.95]\n",
    "    \n",
    "    # c. dependent variable\n",
    "    y = 0.1 + 0.3*x1 + 0.5*x2 + eps\n",
    "    \n",
    "    return x1, x2, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The data you have access to is:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2020)\n",
    "x1,x2,y = DGP(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1:** Estimate the vector of coefficients $\\mathbf{\\beta} = (\\beta_0,\\beta_1,\\beta_2)$ using **ordinary least squares (OLS)** implemented with **matrix algebra** by\n",
    "\n",
    "$$ \\hat{\\mathbf{\\beta}} = (\\mathbf{X}^{\\prime}\\mathbf{X})^{-1}\\mathbf{X}^{\\prime}\\mathbf{y} $$\n",
    "\n",
    "where $\\mathbf{X}^{\\prime}$ is the transpose of $\\mathbf{X}$ and\n",
    "\n",
    "$$\\mathbf{y} = \n",
    "\\pmatrix{ y_1 \\cr y_2 \\cr  \\vdots \\cr y_N \n",
    "}\n",
    ", \\quad \\mathbf{X} = \\pmatrix{\n",
    "1 & x_{1,1} & x_{2,1} \\cr \n",
    "1 & x_{1,2} & x_{2,2} \\cr \n",
    "\\vdots & \\vdots \\cr \n",
    "1 & x_{1,N} & x_{2,N} \n",
    "}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(10000,)\n(10000,)\n(10000,)\n(10000,)\n(10000, 3)\n[[ 1.         -1.76884571 -0.18279442]\n [ 1.          0.07555227  0.78062368]\n [ 1.         -1.1306297  -1.01220533]\n ...\n [ 1.          0.0370484  -1.44286811]\n [ 1.          1.70892684 -0.10668645]\n [ 1.          2.06128052  0.55908184]]\n"
    }
   ],
   "source": [
    "#Q1 Answer\n",
    "#coeffs = linalg.inv(X.transpose().dot(X)).dot(X.transpose()).dot(y)\n",
    "Y=np.array(y)\n",
    "X1=np.array(x1)\n",
    "X2=np.array(x2)\n",
    "print(y.shape)\n",
    "print(X1.shape)\n",
    "print(X2.shape)\n",
    "X0=np.ones(shape=y.shape)\n",
    "print(X0.shape)\n",
    "X=np.column_stack((X0,X1))\n",
    "X=np.column_stack((X,X2))\n",
    "print(X.shape)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[0.0956821  0.29294299 0.50332771]\n"
    }
   ],
   "source": [
    "coeffs = linalg.inv(X.transpose().dot(X)).dot(X.transpose()).dot(Y)\n",
    "print(coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.09568210492389777\n0.2929429877107508\n0.5033277126888069\n"
    }
   ],
   "source": [
    "# we end up with the results:\n",
    "B_0_hat=coeffs[0]\n",
    "print(B_0_hat)\n",
    "B_1_hat=coeffs[1]\n",
    "print(B_1_hat)\n",
    "B_2_hat=coeffs[2]\n",
    "print(B_2_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2:** Construct a 3D plot, where the data is plotted as scattered points, and the prediction of the model is given by the plane\n",
    "\n",
    "$$\\hat{y}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_{1,i} + \\hat{\\beta}_2 x_{2,i}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3:** Esimtate the vector of coefficients $\\mathbf{\\beta} = (\\beta_0,\\beta_1,\\beta_2)$ using a **numerical solver** to solve the ordinary least square problem, shown below, directly. Compare your results with the matrix algebra results.\n",
    "\n",
    "$$ \\min_{\\mathbf{\\beta}} \\sum^N_{i=1} (y_i - (\\beta_0 + \\beta_1 x_{1,i} + \\beta_2 x_{2,i}) )^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4:** Estimate the vector of coefficients $\\mathbf{\\beta} = (\\beta_0,\\beta_1,\\beta_2)$ using **least absolute deviations (LAD)** using a numerical solver to solve the following problem directly: \n",
    "\n",
    "$$  \\min_{\\beta} \\sum^N_{i=1} |y_i - (\\beta_0 + \\beta_1 x_{1,i} + \\beta_2 x_{2,i}) | $$\n",
    "\n",
    "where $|z|$ is the absolute value of $z$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5:** Set $N = 50$. Repeat the estimation using the **OLS** and **LAD** methods $K=5000$ times, drawing a new random sample from the data generating process each time. Compare the estimates from each method using histograms. Which method do you prefer? Explain your choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Durable purchases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a **household** living in two periods.\n",
    "\n",
    "In the **second period** it gets utility from **non-durable consumption**, $c$, and **durable consumption**, $d+\\chi x$:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "v_{2}(m_{2},d)&= \\max_{c}\\frac{(c^{\\alpha}(d+\\chi x)^{1-\\alpha})^{1-\\rho}}{1-\\rho}\\\\\n",
    "\\text{s.t.} \\\\\n",
    "x &= m_{2}-c \\\\\n",
    "c &\\in [0,m_{2}]\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where \n",
    "\n",
    "* $m_2$ is cash-on-hand in the beginning of period 2\n",
    "* $c$ is non-durable consumption\n",
    "* $d$ is pre-commited durable consumption\n",
    "* $x = m_2 - c$ is extra durable consumption\n",
    "* $\\rho > 1$ is the risk aversion coefficient\n",
    "* $\\alpha \\in (0,1)$ is the utility weight on non-durable consumption\n",
    "* $\\chi \\in (0,1)$ implies that extra durable consumption is *less* valuable than pre-comitted durable consumption\n",
    "* the second constraint ensures the household *cannot* die in debt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **value function** $v_2(m_2,d)$ measures the household's value of having $m_2$ at the beginning of period 2 with precomitted durable consumption of $d$. The optimal choice of non-durable consumption is denoted $c^{\\ast}(m_2,d)$. The optimal extra durable consumption function is $x^{\\ast}(m_2,d) = m_2-c^{\\ast}(m_2,d)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the so-called **end-of-period 1 value function** as:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "w(a,d)&\\equiv\\beta\\mathbb{E}_{1}\\left[v_2(m_2,d)\\right]\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "m_2&= (1+r)a+y \\\\\n",
    "y &= \\begin{cases}\n",
    "1-\\Delta & \\text{with prob. }\\frac{1}{3}\\\\\n",
    "1 & \\text{with prob. }\\frac{1}{3}\\\\\n",
    "1+\\Delta & \\text{with prob. }\\frac{1}{3}\n",
    "\\end{cases}\\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "* $a$ is assets at the end of period 1\n",
    "* $\\beta > 0$ is the discount factor\n",
    "* $\\mathbb{E}_1$ is the expectation operator conditional on information in period 1\n",
    "* $y$ is income in period 2\n",
    "* $\\Delta \\in (0,1)$ is the level of income risk (mean-preserving)\n",
    "* $r$ is the return on savings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the **first period**, the household chooses it's pre-comitted level of durable consumption for the next-period,\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "v_{1}(m_{1})&=\\max_{d} w(a,d)\\\\&\\text{s.t.}&\\\\\n",
    "a&= m_{1}-d \\\\\n",
    "d&\\in [0,m_{1}]\\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where $m_1$ is cash-on-hand in period 1. The second constraint ensures the household *cannot* borrow. The **value function** $v_1(m_1)$ measures the household's value of having $m_1$ at the beginning of period 1. The optimal choice of pre-committed durable consumption is denoted $d^{\\ast}(m_1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **parameters** and **grids** for $m_1$, $m_2$ and $d$ should be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a. parameters\n",
    "rho = 2\n",
    "alpha = 0.8\n",
    "beta = 0.96\n",
    "r = 0.04\n",
    "Delta = 0.25\n",
    "\n",
    "# b. grids\n",
    "m1_vec = np.linspace(1e-8,10,100)\n",
    "m2_vec = np.linspace(1e-8,10,100)\n",
    "d_vec = np.linspace(1e-8,5,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additionally we received information on the parameter chi, which should be set to 0.9\n",
    "chi=0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining basic functions\n",
    "\n",
    "def v2(c,alpha,d,rho,m2,chi):\n",
    "    return (c**alpha*(d+chi*(m2-c))*(1-alpha))**(1-rho)/(1-rho) #Have substituted the constraint into the function\n",
    "\n",
    "def w(beta,c,r,m1,y,d,Delta,v2_interp):\n",
    "   \n",
    "    # a. w value if low income\n",
    "    m2_low = (1+r)*(m1-c)*(m1-d) + 1-Delta  #also substituting in v1's constraint a = m1-d\n",
    "    v2_low = v2_interp([m2_low])[0] \n",
    "\n",
    "    # b. w value if mid income\n",
    "    m2_mid = (1+r)*(m1-c)*(m1-d) + 1        #also substituting in v1's constraint a = m1-d\n",
    "    v2_mid = v2_interp([m2_mid])[0] \n",
    "    \n",
    "    # c. w value if high income\n",
    "    m2_high = (1+r)*(m1-c)*(m1-d) + 1+Delta #also substituting in v1's constraint a = m1-d\n",
    "    v2_high = v2_interp([m2_high])[0] \n",
    "\n",
    "    # d. expected w value\n",
    "    w = ((1/3)*v2_low + (1/3)*v2_mid + (1/3)*v2_high)*beta\n",
    "    \n",
    "    # e. final w\n",
    "    return w(beta,c,r,m1,y,d,Delta,v2_interp)\n",
    "\n",
    "def v1(beta,c,r,m1,y,d,Delta,v2_interp):\n",
    "    # total value\n",
    "    v1 = w\n",
    "    return utility(beta,c,r,m1,y,d,Delta,v2_interp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solving the functions\n",
    "\n",
    "def solve_period_2(alpha,rho,chi,Delta):\n",
    "\n",
    "    # a. grids (from before)\n",
    "    m2_vec = np.linspace(1e-8,10,100)\n",
    "    v2_vec = np.empty((100,100))\n",
    "    c_vec = np.empty((100,100))\n",
    "\n",
    "    # b. solve for each m2 in grid\n",
    "\n",
    "    for i,m2 in enumerate(m2_vec):\n",
    "    \n",
    "            # i. objective\n",
    "            obj = lambda c: -v2(c,alpha,d,rho,m2,chi)\n",
    "\n",
    "            # ii. initial value (consume half)\n",
    "            x0 = m2/2\n",
    "\n",
    "            # iii. optimizer\n",
    "            result = optimize.minimize_scalar(obj,x0,method='bounded',bounds=[1e-8,m2])\n",
    "\n",
    "            # iv. save\n",
    "            v2_vec[i] = -result.fun\n",
    "            c_vec[i] = result.x\n",
    "        \n",
    "    return m2_vec,v2_vec,c_vec\n",
    "\n",
    "def solve_period_1(rho,beta,r,Delta,v1,v2_interp):\n",
    "\n",
    "    # a. grids\n",
    "    m1_vec = np.linspace(1e-8,4,100)\n",
    "    v1_vec = np.empty(100)\n",
    "    d_vec = np.empty(100)\n",
    "    \n",
    "    # b. solve for each m1 in grid\n",
    "    for i,m1 in enumerate(m1_vec):\n",
    "        \n",
    "        # i. objective\n",
    "        obj = lambda c: -v1(beta,c,r,m1,y,d,Delta,v2_interp)\n",
    "        \n",
    "        # ii. initial guess (consume half)\n",
    "        x0 = m1*1/2\n",
    "        \n",
    "        # iii. optimize\n",
    "        result = optimize.minimize_scalar(obj,x0,method='bounded',bounds=[1e-8,m1])\n",
    "        \n",
    "        # iv. save\n",
    "        v1_vec[i] = -result.fun\n",
    "        d_vec[i] = result.x\n",
    "     \n",
    "    return m1_vec,v1_vec,d_vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'd' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-bd1cdb480f3c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mm1_vec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0md_vec\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mm1_vec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mv1_vec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0md_vec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msolve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrho\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbeta\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mDelta\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mchi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m# c. plot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-38-bd1cdb480f3c>\u001b[0m in \u001b[0;36msolve\u001b[1;34m(rho, beta, r, Delta, chi, v1)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m# a. solve period 2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mm2_vec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mv2_vec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc_vec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msolve_period_2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrho\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mchi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mDelta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m# b. construct interpolator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-37-33ac3f61ec42>\u001b[0m in \u001b[0;36msolve_period_2\u001b[1;34m(alpha, rho, chi, Delta)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[1;31m# iii. optimizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimize\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimize_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'bounded'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1e-8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mm2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[1;31m# iv. save\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\_minimize.py\u001b[0m in \u001b[0;36mminimize_scalar\u001b[1;34m(fun, bracket, bounds, args, method, tol, options)\u001b[0m\n\u001b[0;32m    778\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdisp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m             \u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'disp'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdisp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_minimize_scalar_bounded\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbounds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'golden'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_minimize_scalar_golden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbracket\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36m_minimize_scalar_bounded\u001b[1;34m(func, bounds, args, xatol, maxiter, disp, **unknown_options)\u001b[0m\n\u001b[0;32m   1772\u001b[0m     \u001b[0mrat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1773\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1774\u001b[1;33m     \u001b[0mfx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1775\u001b[0m     \u001b[0mnum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1776\u001b[0m     \u001b[0mfmin_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-37-33ac3f61ec42>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(c)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[1;31m# i. objective\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m             \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrho\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mm2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mchi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[1;31m# ii. initial value (consume half)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'd' is not defined"
     ]
    }
   ],
   "source": [
    "# b. solve\n",
    "def solve(rho,beta,r,Delta,chi,v1):\n",
    "    \n",
    "    # a. solve period 2\n",
    "    m2_vec,v2_vec,c_vec = solve_period_2(alpha,rho,chi,Delta)\n",
    "    \n",
    "    # b. construct interpolator\n",
    "    v2_interp = interpolate.RegularGridInterpolator((m2_vec,), v2_vec,\n",
    "                                                    bounds_error=False,fill_value=None)\n",
    "    \n",
    "    # b. solve period 1\n",
    "    m1_vec,v1_vec,d_vec = solve_period_1(rho,beta,r,Delta,v1,v2_interp)\n",
    "    \n",
    "    return m1_vec,d_vec\n",
    "\n",
    "m1_vec,v1_vec,d_vec = solve(rho,beta,r,Delta,chi,v1)\n",
    "\n",
    "# c. plot\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.plot(m1_vec,c1_vec)\n",
    "ax.set_xlabel('$m_1$')\n",
    "ax.set_ylabel('$c_1$')\n",
    "ax.set_title('consumption function in period 1')\n",
    "ax.set_xlim([0,4])\n",
    "ax.set_ylim([0,2.5]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "solve_period_2() missing 1 required positional argument: 'Delta'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-0975238995b8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# a. solve\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mm1_vec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mm2_vec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0md_vec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mv2_grid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc_grid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msolve_period_2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrho\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mchi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# b. grids\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mm1_grid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mm2_grid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmeshgrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm1_vec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mm2_vec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindexing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ij'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: solve_period_2() missing 1 required positional argument: 'Delta'"
     ]
    }
   ],
   "source": [
    "# a. solve\n",
    "m1_vec,m2_vec,d_vec,v2_grid,c_grid = solve_period_2(alpha,rho,chi)\n",
    "\n",
    "# b. grids\n",
    "m1_grid,m2_grid = np.meshgrid(m1_vec,m2_vec,indexing='ij')\n",
    "\n",
    "# c. main\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1,projection='3d')\n",
    "cs = ax.plot_surface(m1_grid,m2_grid,c_grid,cmap=cm.jet)\n",
    "\n",
    "# d. add labels\n",
    "ax.set_xlabel('$m_1$')\n",
    "ax.set_ylabel('$m_2$')\n",
    "ax.set_zlabel('$c$')\n",
    "\n",
    "# e. invert xaxis\n",
    "ax.invert_xaxis()\n",
    "\n",
    "# f. add colorbar\n",
    "fig.colorbar(cs);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1:** Find and plot the functions $v_{2}(m_{2},d)$, $c^{\\ast}(m_2,d)$, and $x^{\\ast}(m_2,d)$. Comment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2:** Find and plot the functions $v_{1}(m_{1})$ and $d^{\\ast}(m_1)$. Comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "v2_interp = interpolate.RegularGridInterpolator([m2_vec], d_vec,\n",
    "                                                bounds_error=False,fill_value=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hint:** For interpolation of $v_2(m_2,d)$ consider using `interpolate.RegularGridInterpolator([GRID-VECTOR1,GRID-VECTOR2],VALUE-MATRIX,bounds_error=False,fill_value=None)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, consider an **extension** of the model, where there is also a **period 0**. In this period, the household makes a choice whether to stick with the level of durables it has, $z = 0$, or adjust its stock of durables, $z = 1$. If adjusting, the household loses a part of the value of its durable stock; more specificaly it incurs a proportional loss of $\\Lambda \\in (0,1)$.\n",
    "\n",
    "Mathematically, the **household problem in period 0** is:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "v_{0}(m_{0},d_{0}) &= \\max_{z\\in\\{0,1\\}} \\begin{cases}\n",
    "w(m_{0},d_{0}) & \\text{if } z = 0\\\\\n",
    "v_1(m_0+(1-\\Lambda) d_{0}) & \\text{if } z = 1\\\\\n",
    "\\end{cases}\\\\\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **parameters** and **grids** for $m_0$ and $d_0$ should be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lambda = 0.2\n",
    "m0_vec = np.linspace(1e-8,6,100)\n",
    "d0_vec = np.linspace(1e-8,3,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3:** For which values of $m_0$ and  $d_0$ is the optimal choice not to adjust, i.e. $z = 0$? Show this in a plot. Give an interpretion of your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $\\boldsymbol{x} = \\left[\\begin{array}{c}\n",
    "x_1 \\\\\n",
    "x_2\\\\\n",
    "\\end{array}\\right]$ be a two-dimensional vector. Consider the following algorithm:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Algorithm:** `gradient_descent()`\n",
    "\n",
    "**Goal:** Minimize the function $f(\\boldsymbol{x})$.\n",
    "\n",
    "1. Choose a tolerance $\\epsilon>0$, a scale factor $ \\Theta > 0$, and a small number $\\Delta > 0$\n",
    "2. Guess on $\\boldsymbol{x}_0$ and set $n=1$\n",
    "3. Compute a numerical approximation of the jacobian for $f$ by\n",
    "\n",
    "    $$\n",
    "    \\nabla f(\\boldsymbol{x}_{n-1}) \\approx \\frac{1}{\\Delta}\\left[\\begin{array}{c}\n",
    "    f\\left(\\boldsymbol{x}_{n-1}+\\left[\\begin{array}{c}\n",
    "    \\Delta\\\\\n",
    "    0\n",
    "    \\end{array}\\right]\\right)-f(\\boldsymbol{x}_{n-1})\\\\\n",
    "    f\\left(\\boldsymbol{x}_{n-1}+\\left[\\begin{array}{c}\n",
    "    0\\\\\n",
    "    \\Delta\n",
    "    \\end{array}\\right]\\right)-f(\\boldsymbol{x}_{n-1})\n",
    "    \\end{array}\\right]\n",
    "    $$\n",
    "\n",
    "4. Stop if the maximum element in $|\\nabla f(\\boldsymbol{x}_{n-1})|$ is less than $\\epsilon$\n",
    "5. Set $\\theta = \\Theta$ \n",
    "6. Compute $f^{\\theta}_{n} = f(\\boldsymbol{x}_{n-1} - \\theta \\nabla f(\\boldsymbol{x}_{n-1}))$\n",
    "7. If $f^{\\theta}_{n} < f(\\boldsymbol{x}_{n-1})$ continue to step 9\n",
    "8. Set $\\theta = \\frac{\\theta}{2}$ and return to step 6     \n",
    "9. Set $x_{n} = x_{n-1} - \\theta \\nabla f(\\boldsymbol{x}_{n-1})$\n",
    "10. Set $n = n + 1$ and return to step 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Implement the algorithm above such that the code below can run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optimizer function:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(f,x0,epsilon=1e-6,Theta=0.1,Delta=1e-8,max_iter=10_000):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = sm.symbols('x_1')\n",
    "x2 = sm.symbols('x_2')\n",
    "f = (1.0-x1)**2+2*(x2-x1**2)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Matrix([\n[-8*x_1*(-x_1**2 + x_2) + 2*x_1 - 2.0],\n[                   -4*x_1**2 + 4*x_2]])",
      "text/latex": "$\\displaystyle \\left[\\begin{matrix}- 8 x_{1} \\left(- x_{1}^{2} + x_{2}\\right) + 2 x_{1} - 2.0\\\\- 4 x_{1}^{2} + 4 x_{2}\\end{matrix}\\right]$"
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "Df = sm.Matrix([sm.diff(f,i) for i in [x1,x2]])\n",
    "Df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Matrix([\n[2*(12*x_1**2 - 4*x_2 + 1), -8*x_1],\n[                   -8*x_1,      4]])",
      "text/latex": "$\\displaystyle \\left[\\begin{matrix}2 \\left(12 x_{1}^{2} - 4 x_{2} + 1\\right) & - 8 x_{1}\\\\- 8 x_{1} & 4\\end{matrix}\\right]$"
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "Hf = sm.Matrix([[sm.diff(f,i,j) for j in [x1,x2]] for i in [x1,x2]])\n",
    "Hf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test case:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _rosen(x1,x2):\n",
    "    return (1.0-x[0])**2+2*(x[1]-x[0]**2)**2\n",
    "def rosen(x):\n",
    "    return _rosen(x[0],x[1])\n",
    "def rosen_jac(x):\n",
    "    return np.array([-8*x[0]*(-x[0]+x[1])+2*x[0]-2],[-4*x[0]**2+4*x[1]])\n",
    "def rosen_hess(x):\n",
    "    return np.array([2*(12*x[0]**2-4*x[1]+1)-8*x[0]],[-8*x[0]+4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(f,x0,epsilon=1e-6,Theta=0.1,Delta=1e-8,max_iter=10_000,tol=1e-8):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-48-e7628c67d4ca>, line 37)",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-48-e7628c67d4ca>\"\u001b[1;36m, line \u001b[1;32m37\u001b[0m\n\u001b[1;33m    break\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "#Se lecture 11, afnist 2.1\n",
    "def minimize_gradient_descent(f,x0,jac,thetas=[0.01,0.05,0.1,0.25,0.5,1],max_iter=10_000,tol=epsilon):\n",
    "    \"\"\" minimize function with gradient descent\n",
    "        \n",
    "    Args:\n",
    "\n",
    "        f (callable): function\n",
    "        x0 (float): initial value\n",
    "        jac (callable): jacobian\n",
    "        alpha (list): potential step sizes\n",
    "        max_iter (int): maximum number of iterations\n",
    "        tol (float): tolerance\n",
    "        \n",
    "    Returns:\n",
    "    \n",
    "        x (float): root\n",
    "        n (int): number of iterations used\n",
    "        \n",
    "    \"\"\"\n",
    "    #Step 1: Choose a tolerance epsilon > 0, a scale factor Theta > 0, and a small number delta >0\n",
    "    epsilon = 1e-6\n",
    "    Theta = 0.1\n",
    "    Delta = 1e-8\n",
    "\n",
    "    #Step 2: Guess on x0 and set n=1\n",
    "    x = x0\n",
    "    fx = f(x0)\n",
    "    n=1\n",
    "\n",
    "    #Step 3-10: Compute a numerical approximation of the jacobian for f:\n",
    "    while n < max_iter:\n",
    "\n",
    "        jacx = 1/Delta*np.array([])\n",
    "\n",
    "        #Step 4: Stop if the max element in ... is less than epsilon\n",
    "        fx = f(x)\n",
    "        if abs(fx_prev)<tol:\n",
    "        break\n",
    "        #Step 5: Set theta = Theta\n",
    "        theta = Theta\n",
    "        #Step 6: Compute ... (evt)\n",
    "        x = x_prev - theta * jacx\n",
    "\n",
    "        #Step 7: if fntheta < previous f\n",
    "\n",
    "    \n",
    "        #Step 8: Set theta = theta/2 and return to step\n",
    "\n",
    "        #Step 9: Set xn=xn-1-theta*prev f (Evt. 'find a good step size-skridtet'aka step 3)\n",
    "        fx_ast = np.inf\n",
    "        theta_ast = np.nan\n",
    "        for theta in thetas\n",
    "        x = x_prev - theta*jacx\n",
    "        fx = f(x)\n",
    "            if fx < fx_ast:\n",
    "            fx_ast = fx\n",
    "            theta_ast = theta\n",
    "\n",
    "        #Step 10: Set n = n +1 ad return to step 3\n",
    "        n += 1\n",
    "    return x,n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-49-43d70c2c5a48>, line 5)",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-49-43d70c2c5a48>\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    x,it = gradient_descent(rosen,x0)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "def rosen(x):\n",
    "    return (1.0-x[0])**2+2*(x[1]-x[0]**2)**2\n",
    "x0 = np.array([1.1,1.1])\n",
    "try:\n",
    "x,it = gradient_descent(rosen,x0)\n",
    "    print(f'minimum found at ({x[0]:.4f},{x[1]:.4f}) after {it} iterations')\n",
    "    assert np.allclose(x,[1,1])\n",
    "except:\n",
    "print('not implemented yet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}